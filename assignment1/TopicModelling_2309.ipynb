{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp38-cp38-macosx_10_9_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 10.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5.0 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.5.0)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-2.1.1.tar.gz (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 12.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /opt/anaconda3/lib/python3.8/site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: boto in /opt/anaconda3/lib/python3.8/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.15.2-py2.py3-none-any.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 13.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.19.0,>=1.18.2\n",
      "  Downloading botocore-1.18.2-py2.py3-none-any.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 14.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /opt/anaconda3/lib/python3.8/site-packages (from botocore<1.19.0,>=1.18.2->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-2.1.1-py3-none-any.whl size=112413 sha256=6def6f0adc6845ce89c55b195540b9169f681612faeb630d8124dcf8bcd16286\n",
      "  Stored in directory: /Users/andreaprenner/Library/Caches/pip/wheels/75/81/f7/25ad503e6a6a4bd757502b7b8329da19f9ecdbba5965de36c8\n",
      "Successfully built smart-open\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto3-1.15.2 botocore-1.18.2 gensim-3.8.3 jmespath-0.10.0 s3transfer-0.3.3 smart-open-2.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/andreaprenner/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set WD\n",
    "os.chdir(\"/Users/andreaprenner/Desktop/Master_UvA/1. Semester/FundamentalsOfDS/Assignment1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_lang</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>...</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>state</th>\n",
       "      <th>tags_mention</th>\n",
       "      <th>hash_mention</th>\n",
       "      <th>tags_hash</th>\n",
       "      <th>Trump</th>\n",
       "      <th>Clinton</th>\n",
       "      <th>tweet_text_split</th>\n",
       "      <th>Polarity Score</th>\n",
       "      <th>String New Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 12 10:24:17 +0000 2016</td>\n",
       "      <td>AND SO FOLEY A SEX OFFENDER</td>\n",
       "      <td>764044831966449664</td>\n",
       "      <td>en</td>\n",
       "      <td>2300289704</td>\n",
       "      <td>2300289704</td>\n",
       "      <td>71963857</td>\n",
       "      <td>sedition48</td>\n",
       "      <td>Fort Lauderdale, FL</td>\n",
       "      <td>evolution equality liberal atheist</td>\n",
       "      <td>...</td>\n",
       "      <td>26.080935, -80.20811</td>\n",
       "      <td>Florida</td>\n",
       "      <td>EnemyWithinn,HunterHRC2016,HillaryClinton</td>\n",
       "      <td></td>\n",
       "      <td>enemywithinn,hunterhrc2016,hillaryclinton</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[foley, sex, offender]</td>\n",
       "      <td>negative</td>\n",
       "      <td>foley sex offender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 12 10:31:45 +0000 2016</td>\n",
       "      <td>\\n from  \\nclip said just declare Victory a...</td>\n",
       "      <td>764046707453595648</td>\n",
       "      <td>en</td>\n",
       "      <td>1720816128</td>\n",
       "      <td>1720816128</td>\n",
       "      <td>47261104</td>\n",
       "      <td>treehugger1605</td>\n",
       "      <td>West Fork, AR</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>33.004106, -94.61771</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Corporatocrazy,EconDemocracy1,NewYorker,realDo...</td>\n",
       "      <td></td>\n",
       "      <td>corporatocrazy,econdemocracy1,newyorker,realdo...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[clip, said, declare, victory, get, id]</td>\n",
       "      <td>positive</td>\n",
       "      <td>clip said declare victory get id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 12 10:39:11 +0000 2016</td>\n",
       "      <td>This NOT feasible for CrookedHillary  bcit w...</td>\n",
       "      <td>764048581921648642</td>\n",
       "      <td>en</td>\n",
       "      <td>705902960967094272</td>\n",
       "      <td>705902960967094272</td>\n",
       "      <td>1026787952</td>\n",
       "      <td>vivianbrown21</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>25.837092, -106.645646</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>USAforTrump2016,realDonaldTrump</td>\n",
       "      <td>CrookedHillary</td>\n",
       "      <td>crookedhillaryusafortrump2016,realdonaldtrump</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[feasible, crookedhillary, bcit, would, use, m...</td>\n",
       "      <td>negative</td>\n",
       "      <td>feasible crookedhillary bcit would use many tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 12 10:45:57 +0000 2016</td>\n",
       "      <td>KORN\\nHey check out our new  Video\\nhttpstcoWf...</td>\n",
       "      <td>764050284486144000</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>744989452284497920</td>\n",
       "      <td>humptrump2016</td>\n",
       "      <td>Louisiana, USA</td>\n",
       "      <td>All about the next four years.#https://youtu.b...</td>\n",
       "      <td>...</td>\n",
       "      <td>30.124859, -93.314852</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>KORN,donaldtrump,startrek</td>\n",
       "      <td>korn,donaldtrump,startrekrealdonaldtrump</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[korn, hey, check, new, video, httpstcowffbpmt...</td>\n",
       "      <td>positive</td>\n",
       "      <td>korn hey check new video httpstcowffbpmtpdf do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 12 10:54:08 +0000 2016</td>\n",
       "      <td>ISIS trouble so he had to flip to get out o...</td>\n",
       "      <td>764052340450004992</td>\n",
       "      <td>en</td>\n",
       "      <td>190260040</td>\n",
       "      <td>190260040</td>\n",
       "      <td>190260040</td>\n",
       "      <td>paronlulu</td>\n",
       "      <td>None</td>\n",
       "      <td>Widow, mother, grandmother, great grandmother,...</td>\n",
       "      <td>...</td>\n",
       "      <td>33.004106, -94.61771</td>\n",
       "      <td>Texas</td>\n",
       "      <td>JeffreyGuterman,realDonaldTrump,CNN</td>\n",
       "      <td></td>\n",
       "      <td>jeffreyguterman,realdonaldtrump,cnn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[isis, trouble, flip, get, mess, caused]</td>\n",
       "      <td>negative</td>\n",
       "      <td>isis trouble flip get mess caused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Sep 10 02:22:17 +0000 2016</td>\n",
       "      <td>mean while Trumps speech was a home run toni...</td>\n",
       "      <td>774432781061525504</td>\n",
       "      <td>en</td>\n",
       "      <td>41634520</td>\n",
       "      <td>41634520</td>\n",
       "      <td>14753368</td>\n",
       "      <td>glenp</td>\n",
       "      <td>1 Norwood Ct., Oxford, MA</td>\n",
       "      <td>Owner of Eccentric Musician Company a Music Se...</td>\n",
       "      <td>...</td>\n",
       "      <td>41.187054, -73.508143</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>seanhannity,Reince,movement_trump</td>\n",
       "      <td>Trump</td>\n",
       "      <td>trumpseanhannity,reince,movement_trump</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[mean, trumps, speech, home, run, tonight]</td>\n",
       "      <td>negative</td>\n",
       "      <td>mean trumps speech home run tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Sep 10 02:24:38 +0000 2016</td>\n",
       "      <td>why are you always so angry as if you dont li...</td>\n",
       "      <td>774433371585847296</td>\n",
       "      <td>en</td>\n",
       "      <td>1339835893</td>\n",
       "      <td>1339835893</td>\n",
       "      <td>741409538172014593</td>\n",
       "      <td>FilemonRuizP</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>Nicaraguan-American.  I love justice, peace, s...</td>\n",
       "      <td>...</td>\n",
       "      <td>25.65479, -80.498527</td>\n",
       "      <td>Florida</td>\n",
       "      <td>HillaryClinton,BarackObama</td>\n",
       "      <td></td>\n",
       "      <td>hillaryclinton,barackobama</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[always, angry, dont, like, administration, done]</td>\n",
       "      <td>negative</td>\n",
       "      <td>always angry dont like administration done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Sep 10 02:28:18 +0000 2016</td>\n",
       "      <td>REMEMBER SLICK WILLIE SWORE  AMERICA I DID NO...</td>\n",
       "      <td>774434293489598464</td>\n",
       "      <td>en</td>\n",
       "      <td>25073877</td>\n",
       "      <td>25073877</td>\n",
       "      <td>1675606380</td>\n",
       "      <td>djcaldwelldmd</td>\n",
       "      <td>Mississippi, USA</td>\n",
       "      <td>OSOK77 HOGS TOOTH SEMPER FI! US PATRIOT, HATE ...</td>\n",
       "      <td>...</td>\n",
       "      <td>30.146096, -91.655009</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td></td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[remember, slick, willie, swore, america, sex,...</td>\n",
       "      <td>positive</td>\n",
       "      <td>remember slick willie swore america sex wthat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Sep 10 02:40:51 +0000 2016</td>\n",
       "      <td>Thank you  for clarifying that  hasnt been con...</td>\n",
       "      <td>774437452274622464</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2911334707</td>\n",
       "      <td>amymkennedy75</td>\n",
       "      <td>None</td>\n",
       "      <td>Wife, Mother, RN, Nurse Educator, Cleveland Br...</td>\n",
       "      <td>...</td>\n",
       "      <td>36.960216, -76.62797</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>donlemon,HillaryClinton</td>\n",
       "      <td></td>\n",
       "      <td>donlemon,hillaryclinton</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[thank, clarifying, hasnt, convicted, anything]</td>\n",
       "      <td>positive</td>\n",
       "      <td>thank clarifying hasnt convicted anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Sep 10 02:43:38 +0000 2016</td>\n",
       "      <td>What is the scoop you n Gen Flynn Why the Trum...</td>\n",
       "      <td>774438151473332224</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3265487802</td>\n",
       "      <td>wells_bonita</td>\n",
       "      <td>Las Vegas, NV</td>\n",
       "      <td>Unionize to protect all workers. Retired int'l...</td>\n",
       "      <td>...</td>\n",
       "      <td>36.129459, -115.384091</td>\n",
       "      <td>Nevada</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[scoop, n, gen, flynn, trump, supporter, trans...</td>\n",
       "      <td>positive</td>\n",
       "      <td>scoop n gen flynn trump supporter translater t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7900 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_at  \\\n",
       "0   Fri Aug 12 10:24:17 +0000 2016   \n",
       "0   Fri Aug 12 10:31:45 +0000 2016   \n",
       "0   Fri Aug 12 10:39:11 +0000 2016   \n",
       "0   Fri Aug 12 10:45:57 +0000 2016   \n",
       "0   Fri Aug 12 10:54:08 +0000 2016   \n",
       "..                             ...   \n",
       "0   Sat Sep 10 02:22:17 +0000 2016   \n",
       "0   Sat Sep 10 02:24:38 +0000 2016   \n",
       "0   Sat Sep 10 02:28:18 +0000 2016   \n",
       "0   Sat Sep 10 02:40:51 +0000 2016   \n",
       "0   Sat Sep 10 02:43:38 +0000 2016   \n",
       "\n",
       "                                                 text                  id  \\\n",
       "0                         AND SO FOLEY A SEX OFFENDER  764044831966449664   \n",
       "0      \\n from  \\nclip said just declare Victory a...  764046707453595648   \n",
       "0     This NOT feasible for CrookedHillary  bcit w...  764048581921648642   \n",
       "0   KORN\\nHey check out our new  Video\\nhttpstcoWf...  764050284486144000   \n",
       "0      ISIS trouble so he had to flip to get out o...  764052340450004992   \n",
       "..                                                ...                 ...   \n",
       "0     mean while Trumps speech was a home run toni...  774432781061525504   \n",
       "0    why are you always so angry as if you dont li...  774433371585847296   \n",
       "0    REMEMBER SLICK WILLIE SWORE  AMERICA I DID NO...  774434293489598464   \n",
       "0   Thank you  for clarifying that  hasnt been con...  774437452274622464   \n",
       "0   What is the scoop you n Gen Flynn Why the Trum...  774438151473332224   \n",
       "\n",
       "   tweet_lang in_reply_to_user_id in_reply_to_user_id_str             user_id  \\\n",
       "0          en          2300289704              2300289704            71963857   \n",
       "0          en          1720816128              1720816128            47261104   \n",
       "0          en  705902960967094272      705902960967094272          1026787952   \n",
       "0          en                None                    None  744989452284497920   \n",
       "0          en           190260040               190260040           190260040   \n",
       "..        ...                 ...                     ...                 ...   \n",
       "0          en            41634520                41634520            14753368   \n",
       "0          en          1339835893              1339835893  741409538172014593   \n",
       "0          en            25073877                25073877          1675606380   \n",
       "0          en                None                    None          2911334707   \n",
       "0          en                None                    None          3265487802   \n",
       "\n",
       "   user_screen_name              user_location  \\\n",
       "0        sedition48        Fort Lauderdale, FL   \n",
       "0    treehugger1605              West Fork, AR   \n",
       "0     vivianbrown21                       None   \n",
       "0     humptrump2016             Louisiana, USA   \n",
       "0         paronlulu                       None   \n",
       "..              ...                        ...   \n",
       "0             glenp  1 Norwood Ct., Oxford, MA   \n",
       "0      FilemonRuizP                  Miami, FL   \n",
       "0     djcaldwelldmd           Mississippi, USA   \n",
       "0     amymkennedy75                       None   \n",
       "0      wells_bonita              Las Vegas, NV   \n",
       "\n",
       "                                     user_description  ...  \\\n",
       "0                  evolution equality liberal atheist  ...   \n",
       "0                                                None  ...   \n",
       "0                                                None  ...   \n",
       "0   All about the next four years.#https://youtu.b...  ...   \n",
       "0   Widow, mother, grandmother, great grandmother,...  ...   \n",
       "..                                                ...  ...   \n",
       "0   Owner of Eccentric Musician Company a Music Se...  ...   \n",
       "0   Nicaraguan-American.  I love justice, peace, s...  ...   \n",
       "0   OSOK77 HOGS TOOTH SEMPER FI! US PATRIOT, HATE ...  ...   \n",
       "0   Wife, Mother, RN, Nurse Educator, Cleveland Br...  ...   \n",
       "0   Unionize to protect all workers. Retired int'l...  ...   \n",
       "\n",
       "               coordinates        state  \\\n",
       "0     26.080935, -80.20811      Florida   \n",
       "0     33.004106, -94.61771        Texas   \n",
       "0   25.837092, -106.645646    Chihuahua   \n",
       "0    30.124859, -93.314852    Louisiana   \n",
       "0     33.004106, -94.61771        Texas   \n",
       "..                     ...          ...   \n",
       "0    41.187054, -73.508143  Connecticut   \n",
       "0     25.65479, -80.498527      Florida   \n",
       "0    30.146096, -91.655009    Louisiana   \n",
       "0     36.960216, -76.62797     Virginia   \n",
       "0   36.129459, -115.384091       Nevada   \n",
       "\n",
       "                                         tags_mention  \\\n",
       "0           EnemyWithinn,HunterHRC2016,HillaryClinton   \n",
       "0   Corporatocrazy,EconDemocracy1,NewYorker,realDo...   \n",
       "0                     USAforTrump2016,realDonaldTrump   \n",
       "0                                     realDonaldTrump   \n",
       "0                 JeffreyGuterman,realDonaldTrump,CNN   \n",
       "..                                                ...   \n",
       "0                   seanhannity,Reince,movement_trump   \n",
       "0                          HillaryClinton,BarackObama   \n",
       "0                                     realDonaldTrump   \n",
       "0                             donlemon,HillaryClinton   \n",
       "0                                                       \n",
       "\n",
       "                 hash_mention  \\\n",
       "0                               \n",
       "0                               \n",
       "0              CrookedHillary   \n",
       "0   KORN,donaldtrump,startrek   \n",
       "0                               \n",
       "..                        ...   \n",
       "0                       Trump   \n",
       "0                               \n",
       "0                               \n",
       "0                               \n",
       "0                               \n",
       "\n",
       "                                            tags_hash  Trump Clinton  \\\n",
       "0           enemywithinn,hunterhrc2016,hillaryclinton  False    True   \n",
       "0   corporatocrazy,econdemocracy1,newyorker,realdo...   True   False   \n",
       "0       crookedhillaryusafortrump2016,realdonaldtrump   True    True   \n",
       "0            korn,donaldtrump,startrekrealdonaldtrump   True   False   \n",
       "0                 jeffreyguterman,realdonaldtrump,cnn   True   False   \n",
       "..                                                ...    ...     ...   \n",
       "0              trumpseanhannity,reince,movement_trump   True   False   \n",
       "0                          hillaryclinton,barackobama  False    True   \n",
       "0                                     realdonaldtrump   True   False   \n",
       "0                             donlemon,hillaryclinton  False    True   \n",
       "0                                                      False   False   \n",
       "\n",
       "                                     tweet_text_split Polarity Score  \\\n",
       "0                              [foley, sex, offender]       negative   \n",
       "0             [clip, said, declare, victory, get, id]       positive   \n",
       "0   [feasible, crookedhillary, bcit, would, use, m...       negative   \n",
       "0   [korn, hey, check, new, video, httpstcowffbpmt...       positive   \n",
       "0            [isis, trouble, flip, get, mess, caused]       negative   \n",
       "..                                                ...            ...   \n",
       "0          [mean, trumps, speech, home, run, tonight]       negative   \n",
       "0   [always, angry, dont, like, administration, done]       negative   \n",
       "0   [remember, slick, willie, swore, america, sex,...       positive   \n",
       "0     [thank, clarifying, hasnt, convicted, anything]       positive   \n",
       "0   [scoop, n, gen, flynn, trump, supporter, trans...       positive   \n",
       "\n",
       "                                     String New Tweet  \n",
       "0                                  foley sex offender  \n",
       "0                    clip said declare victory get id  \n",
       "0   feasible crookedhillary bcit would use many tw...  \n",
       "0   korn hey check new video httpstcowffbpmtpdf do...  \n",
       "0                   isis trouble flip get mess caused  \n",
       "..                                                ...  \n",
       "0                 mean trumps speech home run tonight  \n",
       "0          always angry dont like administration done  \n",
       "0   remember slick willie swore america sex wthat ...  \n",
       "0           thank clarifying hasnt convicted anything  \n",
       "0   scoop n gen flynn trump supporter translater t...  \n",
       "\n",
       "[7900 rows x 34 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_formatted = pd.read_pickle(\"sentiment_anlaysis_data_formatted.pkl\")\n",
    "data_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_lang</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>...</th>\n",
       "      <th>state</th>\n",
       "      <th>tags_mention</th>\n",
       "      <th>hash_mention</th>\n",
       "      <th>tags_hash</th>\n",
       "      <th>Trump</th>\n",
       "      <th>Clinton</th>\n",
       "      <th>tweet_text_split</th>\n",
       "      <th>Polarity Score</th>\n",
       "      <th>String New Tweet</th>\n",
       "      <th>text_topicmodel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 12 13:29:23 +0000 2016</td>\n",
       "      <td>DOJ is really Deptof NO Justice L Lynch should...</td>\n",
       "      <td>764091413919178752</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4875129611</td>\n",
       "      <td>WineGuyVenice</td>\n",
       "      <td>Venice, FL</td>\n",
       "      <td>Serious golfer, Home chef, Wine taster, Conser...</td>\n",
       "      <td>...</td>\n",
       "      <td>Florida</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[doj, really, deptof, justice, l, lynch, remov...</td>\n",
       "      <td>negative</td>\n",
       "      <td>doj really deptof justice l lynch removeddisgr...</td>\n",
       "      <td>[doj, really, deptof, justice, l, lynch, remov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 12 14:54:52 +0000 2016</td>\n",
       "      <td>Im so looking forward to that moment  I want t...</td>\n",
       "      <td>764112923597746177</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3130204726</td>\n",
       "      <td>RebekahRN61</td>\n",
       "      <td>None</td>\n",
       "      <td>Mother first, everything else second.  Hospice...</td>\n",
       "      <td>...</td>\n",
       "      <td>Ohio</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[im, looking, forward, moment, want, see, lemo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>im looking forward moment want see lemons eyes...</td>\n",
       "      <td>[im, looking, forward, moment, want, see, lemo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 12 15:17:43 +0000 2016</td>\n",
       "      <td>Just more BS Sarcasm</td>\n",
       "      <td>764118677201428481</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>827688751</td>\n",
       "      <td>firiechick1</td>\n",
       "      <td>Running Springs CA</td>\n",
       "      <td>hashtaggers-Daniel mostly supernatural fans.li...</td>\n",
       "      <td>...</td>\n",
       "      <td>California</td>\n",
       "      <td></td>\n",
       "      <td>Sarcasm</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[bs, sarcasm]</td>\n",
       "      <td>negative</td>\n",
       "      <td>bs sarcasm</td>\n",
       "      <td>[b, sarcasm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 12 17:04:08 +0000 2016</td>\n",
       "      <td>If McConnell is looking  sympathy he can find ...</td>\n",
       "      <td>764145454615527425</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2217090614</td>\n",
       "      <td>DeeAnn830</td>\n",
       "      <td>United States</td>\n",
       "      <td>Hoosier by Birth/Gator Since 81/Red State by F...</td>\n",
       "      <td>...</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[mcconnell, looking, sympathy, find, sht, amp,...</td>\n",
       "      <td>negative</td>\n",
       "      <td>mcconnell looking sympathy find sht amp syphil...</td>\n",
       "      <td>[mcconnell, looking, sympathy, find, sht, amp,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Aug 12 17:42:39 +0000 2016</td>\n",
       "      <td>Start with repealing and replace your disastro...</td>\n",
       "      <td>764155149032062976</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>15284812</td>\n",
       "      <td>kermike</td>\n",
       "      <td>Grand Island, NY</td>\n",
       "      <td>Strong Political views, avid sports fans, Sabr...</td>\n",
       "      <td>...</td>\n",
       "      <td>New York</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[start, repealing, replace, disastrous, langua...</td>\n",
       "      <td>positive</td>\n",
       "      <td>start repealing replace disastrous language ca...</td>\n",
       "      <td>[start, repealing, replace, disastrous, langua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Sep 10 01:39:19 +0000 2016</td>\n",
       "      <td>The liberals plan is to beat the race drum as ...</td>\n",
       "      <td>774421966354731009</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>924224208</td>\n",
       "      <td>JacquelineWoodm</td>\n",
       "      <td>SF Bay Area CA</td>\n",
       "      <td>It does not take a majority to prevail, but ra...</td>\n",
       "      <td>...</td>\n",
       "      <td>California</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[liberals, plan, beat, race, drum, hard, dont,...</td>\n",
       "      <td>negative</td>\n",
       "      <td>liberals plan beat race drum hard dont let div...</td>\n",
       "      <td>[liberal, plan, beat, race, drum, hard, dont, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Sep 10 01:52:26 +0000 2016</td>\n",
       "      <td>\\nCheck out  Tweet</td>\n",
       "      <td>774425265212620800</td>\n",
       "      <td>en</td>\n",
       "      <td>42692053</td>\n",
       "      <td>42692053</td>\n",
       "      <td>709085805613072384</td>\n",
       "      <td>SalvatoreVitol5</td>\n",
       "      <td>United States</td>\n",
       "      <td>determined\\n78 years old \\non a mission to ele...</td>\n",
       "      <td>...</td>\n",
       "      <td>New York</td>\n",
       "      <td>BillStaniford,SalvatoreVitol5</td>\n",
       "      <td></td>\n",
       "      <td>billstaniford,salvatorevitol5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[check, tweet]</td>\n",
       "      <td>positive</td>\n",
       "      <td>check tweet</td>\n",
       "      <td>[check, tweet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Sep 10 01:55:21 +0000 2016</td>\n",
       "      <td>\\nCheck out  Tweet</td>\n",
       "      <td>774426002562965505</td>\n",
       "      <td>en</td>\n",
       "      <td>2315583427</td>\n",
       "      <td>2315583427</td>\n",
       "      <td>709085805613072384</td>\n",
       "      <td>SalvatoreVitol5</td>\n",
       "      <td>United States</td>\n",
       "      <td>determined\\n78 years old \\non a mission to ele...</td>\n",
       "      <td>...</td>\n",
       "      <td>New York</td>\n",
       "      <td>EntheosShines,SalvatoreVitol5</td>\n",
       "      <td></td>\n",
       "      <td>entheosshines,salvatorevitol5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[check, tweet]</td>\n",
       "      <td>positive</td>\n",
       "      <td>check tweet</td>\n",
       "      <td>[check, tweet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Sep 10 02:16:12 +0000 2016</td>\n",
       "      <td>Sheeeshh</td>\n",
       "      <td>774431248936792064</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>836199696</td>\n",
       "      <td>TweetinTom09</td>\n",
       "      <td>Ben Hill</td>\n",
       "      <td>#GatorNation ☠</td>\n",
       "      <td>...</td>\n",
       "      <td>Florida</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[sheeeshh]</td>\n",
       "      <td>positive</td>\n",
       "      <td>sheeeshh</td>\n",
       "      <td>[sheeeshh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Sep 10 02:43:38 +0000 2016</td>\n",
       "      <td>What is the scoop you n Gen Flynn Why the Trum...</td>\n",
       "      <td>774438151473332224</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3265487802</td>\n",
       "      <td>wells_bonita</td>\n",
       "      <td>Las Vegas, NV</td>\n",
       "      <td>Unionize to protect all workers. Retired int'l...</td>\n",
       "      <td>...</td>\n",
       "      <td>Nevada</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[scoop, n, gen, flynn, trump, supporter, trans...</td>\n",
       "      <td>positive</td>\n",
       "      <td>scoop n gen flynn trump supporter translater t...</td>\n",
       "      <td>[scoop, n, gen, flynn, trump, supporter, trans...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>829 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_at  \\\n",
       "0   Fri Aug 12 13:29:23 +0000 2016   \n",
       "0   Fri Aug 12 14:54:52 +0000 2016   \n",
       "0   Fri Aug 12 15:17:43 +0000 2016   \n",
       "0   Fri Aug 12 17:04:08 +0000 2016   \n",
       "0   Fri Aug 12 17:42:39 +0000 2016   \n",
       "..                             ...   \n",
       "0   Sat Sep 10 01:39:19 +0000 2016   \n",
       "0   Sat Sep 10 01:52:26 +0000 2016   \n",
       "0   Sat Sep 10 01:55:21 +0000 2016   \n",
       "0   Sat Sep 10 02:16:12 +0000 2016   \n",
       "0   Sat Sep 10 02:43:38 +0000 2016   \n",
       "\n",
       "                                                 text                  id  \\\n",
       "0   DOJ is really Deptof NO Justice L Lynch should...  764091413919178752   \n",
       "0   Im so looking forward to that moment  I want t...  764112923597746177   \n",
       "0                              Just more BS Sarcasm    764118677201428481   \n",
       "0   If McConnell is looking  sympathy he can find ...  764145454615527425   \n",
       "0   Start with repealing and replace your disastro...  764155149032062976   \n",
       "..                                                ...                 ...   \n",
       "0   The liberals plan is to beat the race drum as ...  774421966354731009   \n",
       "0                                 \\nCheck out  Tweet   774425265212620800   \n",
       "0                                 \\nCheck out  Tweet   774426002562965505   \n",
       "0                                          Sheeeshh    774431248936792064   \n",
       "0   What is the scoop you n Gen Flynn Why the Trum...  774438151473332224   \n",
       "\n",
       "   tweet_lang in_reply_to_user_id in_reply_to_user_id_str             user_id  \\\n",
       "0          en                None                    None          4875129611   \n",
       "0          en                None                    None          3130204726   \n",
       "0          en                None                    None           827688751   \n",
       "0          en                None                    None          2217090614   \n",
       "0          en                None                    None            15284812   \n",
       "..        ...                 ...                     ...                 ...   \n",
       "0          en                None                    None           924224208   \n",
       "0          en            42692053                42692053  709085805613072384   \n",
       "0          en          2315583427              2315583427  709085805613072384   \n",
       "0          en                None                    None           836199696   \n",
       "0          en                None                    None          3265487802   \n",
       "\n",
       "   user_screen_name       user_location  \\\n",
       "0     WineGuyVenice          Venice, FL   \n",
       "0       RebekahRN61                None   \n",
       "0       firiechick1  Running Springs CA   \n",
       "0         DeeAnn830       United States   \n",
       "0           kermike    Grand Island, NY   \n",
       "..              ...                 ...   \n",
       "0   JacquelineWoodm      SF Bay Area CA   \n",
       "0   SalvatoreVitol5       United States   \n",
       "0   SalvatoreVitol5       United States   \n",
       "0      TweetinTom09           Ben Hill    \n",
       "0      wells_bonita       Las Vegas, NV   \n",
       "\n",
       "                                     user_description  ...       state  \\\n",
       "0   Serious golfer, Home chef, Wine taster, Conser...  ...     Florida   \n",
       "0   Mother first, everything else second.  Hospice...  ...        Ohio   \n",
       "0   hashtaggers-Daniel mostly supernatural fans.li...  ...  California   \n",
       "0   Hoosier by Birth/Gator Since 81/Red State by F...  ...   Tennessee   \n",
       "0   Strong Political views, avid sports fans, Sabr...  ...    New York   \n",
       "..                                                ...  ...         ...   \n",
       "0   It does not take a majority to prevail, but ra...  ...  California   \n",
       "0   determined\\n78 years old \\non a mission to ele...  ...    New York   \n",
       "0   determined\\n78 years old \\non a mission to ele...  ...    New York   \n",
       "0                                      #GatorNation ☠  ...     Florida   \n",
       "0   Unionize to protect all workers. Retired int'l...  ...      Nevada   \n",
       "\n",
       "                     tags_mention  hash_mention  \\\n",
       "0                                                 \n",
       "0                                                 \n",
       "0                                       Sarcasm   \n",
       "0                                                 \n",
       "0                                                 \n",
       "..                            ...           ...   \n",
       "0                                                 \n",
       "0   BillStaniford,SalvatoreVitol5                 \n",
       "0   EntheosShines,SalvatoreVitol5                 \n",
       "0                                                 \n",
       "0                                                 \n",
       "\n",
       "                        tags_hash  Trump Clinton  \\\n",
       "0                                  False   False   \n",
       "0                                  False   False   \n",
       "0                         sarcasm  False   False   \n",
       "0                                  False   False   \n",
       "0                                  False   False   \n",
       "..                            ...    ...     ...   \n",
       "0                                  False   False   \n",
       "0   billstaniford,salvatorevitol5  False   False   \n",
       "0   entheosshines,salvatorevitol5  False   False   \n",
       "0                                  False   False   \n",
       "0                                  False   False   \n",
       "\n",
       "                                     tweet_text_split Polarity Score  \\\n",
       "0   [doj, really, deptof, justice, l, lynch, remov...       negative   \n",
       "0   [im, looking, forward, moment, want, see, lemo...       negative   \n",
       "0                                       [bs, sarcasm]       negative   \n",
       "0   [mcconnell, looking, sympathy, find, sht, amp,...       negative   \n",
       "0   [start, repealing, replace, disastrous, langua...       positive   \n",
       "..                                                ...            ...   \n",
       "0   [liberals, plan, beat, race, drum, hard, dont,...       negative   \n",
       "0                                      [check, tweet]       positive   \n",
       "0                                      [check, tweet]       positive   \n",
       "0                                          [sheeeshh]       positive   \n",
       "0   [scoop, n, gen, flynn, trump, supporter, trans...       positive   \n",
       "\n",
       "                                     String New Tweet  \\\n",
       "0   doj really deptof justice l lynch removeddisgr...   \n",
       "0   im looking forward moment want see lemons eyes...   \n",
       "0                                          bs sarcasm   \n",
       "0   mcconnell looking sympathy find sht amp syphil...   \n",
       "0   start repealing replace disastrous language ca...   \n",
       "..                                                ...   \n",
       "0   liberals plan beat race drum hard dont let div...   \n",
       "0                                         check tweet   \n",
       "0                                         check tweet   \n",
       "0                                            sheeeshh   \n",
       "0   scoop n gen flynn trump supporter translater t...   \n",
       "\n",
       "                                      text_topicmodel  \n",
       "0   [doj, really, deptof, justice, l, lynch, remov...  \n",
       "0   [im, looking, forward, moment, want, see, lemo...  \n",
       "0                                        [b, sarcasm]  \n",
       "0   [mcconnell, looking, sympathy, find, sht, amp,...  \n",
       "0   [start, repealing, replace, disastrous, langua...  \n",
       "..                                                ...  \n",
       "0   [liberal, plan, beat, race, drum, hard, dont, ...  \n",
       "0                                      [check, tweet]  \n",
       "0                                      [check, tweet]  \n",
       "0                                          [sheeeshh]  \n",
       "0   [scoop, n, gen, flynn, trump, supporter, trans...  \n",
       "\n",
       "[829 rows x 35 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trump false and Clinton False\n",
    "filt = (data_formatted['Trump'] == False) & (data_formatted['Clinton'] == False)\n",
    "data_formatted[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               [foley, sex, offender]\n",
       "0              [clip, said, declare, victory, get, id]\n",
       "0    [feasible, crookedhillary, bcit, would, use, m...\n",
       "0    [korn, hey, check, new, video, httpstcowffbpmt...\n",
       "0              [isi, trouble, flip, get, mess, caused]\n",
       "                           ...                        \n",
       "0            [mean, trump, speech, home, run, tonight]\n",
       "0    [always, angry, dont, like, administration, done]\n",
       "0    [remember, slick, willie, swore, america, sex,...\n",
       "0      [thank, clarifying, hasnt, convicted, anything]\n",
       "0    [scoop, n, gen, flynn, trump, supporter, trans...\n",
       "Name: text_topicmodel, Length: 7900, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data cleaning - removing punctuation from text; still need to remove hashes\n",
    "data_formatted['text_topicmodel'] = data_formatted['text'].str.replace('@[^\\s]+','')\n",
    "data_formatted['text_topicmodel'] = data_formatted['text_topicmodel'].str.replace('[^\\w\\s]','')\n",
    "data_formatted['text_topicmodel'] = data_formatted['text_topicmodel'].str.replace('\\[.*?\\]','')\n",
    "data_formatted['text_topicmodel'] = data_formatted['text_topicmodel'].str.replace('[‘’“”…]','')\n",
    "data_formatted['text_topicmodel'] = data_formatted['text_topicmodel'].str.replace('\\w*\\d\\w*','')\n",
    "data_formatted['text_topicmodel'] = data_formatted['text_topicmodel'].apply(lambda x: x.lower())\n",
    "data_formatted['text_topicmodel'] = data_formatted['text_topicmodel'].apply(lambda x: x.split())\n",
    "data_formatted['text_topicmodel'] = data_formatted['text_topicmodel'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "data_formatted['text_topicmodel'] = data_formatted['text_topicmodel'].apply(lemmatize_text)\n",
    "data_formatted['text_topicmodel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data set for trump vs clinton\n",
    "trump_mentioned_positive = data_formatted[(data_formatted['Trump'] == True) & (data_formatted['Polarity Score'] == 'positive')]\n",
    "trump_mentioned_negative = data_formatted[(data_formatted['Trump'] == True) & (data_formatted['Polarity Score'] == 'negative')]\n",
    "clinton_mentioned_positive = data_formatted[(data_formatted['Clinton'] == True) & (data_formatted['Polarity Score'] == 'positive')]\n",
    "clinton_mentioned_negative = data_formatted[(data_formatted['Clinton'] == True) & (data_formatted['Polarity Score'] == 'negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              [clip, said, declare, victory, get, id]\n",
       "0    [korn, hey, check, new, video, httpstcowffbpmt...\n",
       "0    [medium, doest, understand, trump, american, p...\n",
       "0    [maybe, could, read, book, history, isil, tell...\n",
       "0    [wont, call, doesnt, want, see, u, roll, tape,...\n",
       "                           ...                        \n",
       "0    [hey, angry, white, male, supporter, boy, russ...\n",
       "0    [guliana, getting, crazier, amp, crazier, come...\n",
       "0                                 [let, show, frontal]\n",
       "0    [neverhillary, obama, hillaryclinton, biggest,...\n",
       "0    [remember, slick, willie, swore, america, sex,...\n",
       "Name: text_topicmodel, Length: 2879, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_mentioned_positive['text_topicmodel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trump mentioned / Positive Polarity Score / All words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.017*\"trump\" + 0.010*\"amp\" + 0.010*\"maga\" + 0.008*\"u\" + 0.006*\"clinton\" + 0.006*\"american\" + 0.006*\"great\" + 0.006*\"one\"'),\n",
       " (1,\n",
       "  '0.029*\"trump\" + 0.009*\"amp\" + 0.009*\"u\" + 0.008*\"nevertrump\" + 0.007*\"make\" + 0.007*\"hillary\" + 0.006*\"get\" + 0.006*\"dont\"')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter out rows where text doesnt contain any entries after removing tags and hashes\n",
    "trump_mentioned_positive = trump_mentioned_positive[trump_mentioned_positive['text_topicmodel'].map(lambda d: len(d)) > 0]\n",
    "trump_text = trump_mentioned_positive.text_topicmodel.tolist()\n",
    "dictionary_trump = corpora.Dictionary(trump_text)\n",
    "doc_term_matrix_trump = [dictionary_trump.doc2bow(doc) for doc in trump_text]\n",
    "# Creating the object for LDA model using gensim library\n",
    "Lda_trump = gensim.models.ldamodel.LdaModel\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel_trump = Lda_trump(doc_term_matrix_trump, num_topics=2, id2word = dictionary_trump, passes=100)\n",
    "topics_trump = ldamodel_trump.print_topics(num_topics=2, num_words=8)\n",
    "topics_trump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trump mentioned / Negative Polarity Score / All words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.033*\"trump\" + 0.010*\"today\" + 0.009*\"pressure\" + 0.009*\"rain\" + 0.009*\"tempcrab\" + 0.009*\"forecast\" + 0.009*\"orchard\" + 0.007*\"fine\"'),\n",
       " (1,\n",
       "  '0.020*\"trump\" + 0.015*\"u\" + 0.010*\"amp\" + 0.009*\"dont\" + 0.008*\"get\" + 0.008*\"like\" + 0.008*\"people\" + 0.008*\"hillary\"')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_mentioned_negative = trump_mentioned_negative[trump_mentioned_negative['text_topicmodel'].map(lambda d: len(d)) > 0]\n",
    "trump_text = trump_mentioned_negative.text_topicmodel.tolist()\n",
    "dictionary_trump = corpora.Dictionary(trump_text)\n",
    "doc_term_matrix_trump = [dictionary_trump.doc2bow(doc) for doc in trump_text]\n",
    "# Creating the object for LDA model using gensim library\n",
    "Lda_trump = gensim.models.ldamodel.LdaModel\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel_trump = Lda_trump(doc_term_matrix_trump, num_topics=2, id2word = dictionary_trump, passes=100)\n",
    "topics_trump = ldamodel_trump.print_topics(num_topics=2, num_words=8)\n",
    "topics_trump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clinton mentioned / Positive Polarity Score / All words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.015*\"imwithher\" + 0.015*\"hillary\" + 0.014*\"trump\" + 0.012*\"amp\"'),\n",
       " (1, '0.011*\"trump\" + 0.010*\"amp\" + 0.009*\"u\" + 0.008*\"hillary\"')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter out rows where text doesnt contain any entries after removing tags and hashes\n",
    "clinton_mentioned_positive = clinton_mentioned_positive[clinton_mentioned_positive['text_topicmodel'].map(lambda d: len(d)) > 0]\n",
    "clinton_text = clinton_mentioned_positive.text_topicmodel.tolist()\n",
    "dictionary_clinton = corpora.Dictionary(clinton_text)\n",
    "doc_term_matrix_clinton = [dictionary_clinton.doc2bow(doc) for doc in clinton_text]\n",
    "# Creating the object for LDA model using gensim library\n",
    "Lda_clinton = gensim.models.ldamodel.LdaModel\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel_clinton = Lda_clinton(doc_term_matrix_clinton, num_topics=2, id2word = dictionary_clinton, passes=100)\n",
    "topics_clinton = ldamodel_clinton.print_topics(num_topics=10, num_words=4)\n",
    "topics_clinton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clinton mentioned / Negative Polarity Score / All words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.013*\"amp\" + 0.012*\"hillary\" + 0.012*\"u\" + 0.011*\"trump\"'),\n",
       " (1, '0.015*\"trump\" + 0.013*\"imwithher\" + 0.011*\"hillary\" + 0.011*\"clinton\"')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter out rows where text doesnt contain any entries after removing tags and hashes\n",
    "clinton_mentioned_negative = clinton_mentioned_negative[clinton_mentioned_negative['text_topicmodel'].map(lambda d: len(d)) > 0]\n",
    "clinton_text = clinton_mentioned_positive.text_topicmodel.tolist()\n",
    "dictionary_clinton = corpora.Dictionary(clinton_text)\n",
    "doc_term_matrix_clinton = [dictionary_clinton.doc2bow(doc) for doc in clinton_text]\n",
    "# Creating the object for LDA model using gensim library\n",
    "Lda_clinton = gensim.models.ldamodel.LdaModel\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel_clinton = Lda_clinton(doc_term_matrix_clinton, num_topics=2, id2word = dictionary_clinton, passes=100)\n",
    "topics_clinton = ldamodel_clinton.print_topics(num_topics=10, num_words=4)\n",
    "topics_clinton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Just using nouns in Topic Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trump mentioned / Positive Polarity Score / Only Nouns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(clip, NN), (said, VBD), (declare, JJ), (vict...\n",
       "0    [(korn, VBN), (hey, NNS), (check, VBP), (new, ...\n",
       "0    [(medium, NN), (doest, JJS), (understand, JJ),...\n",
       "0    [(maybe, RB), (could, MD), (read, VB), (book, ...\n",
       "0    [(wont, NN), (call, NN), (doesnt, NN), (want, ...\n",
       "                           ...                        \n",
       "0    [(hey, NN), (angry, JJ), (white, JJ), (male, N...\n",
       "0    [(guliana, NN), (getting, VBG), (crazier, JJR)...\n",
       "0               [(let, VB), (show, NN), (frontal, JJ)]\n",
       "0    [(neverhillary, JJ), (obama, MD), (hillaryclin...\n",
       "0    [(remember, VB), (slick, JJ), (willie, NN), (s...\n",
       "Name: text_topicmodel, Length: 2871, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply function that determines the type of each word\n",
    "trump_mentioned_text = trump_mentioned_positive['text_topicmodel'].apply(lambda x: nltk.pos_tag(x))\n",
    "trump_mentioned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_noun = lambda pos: pos[:2] == 'NN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out the nouns for each row\n",
    "trump_mentioned_nouns = pd.DataFrame(np.zeros((len(trump_mentioned_text), 1)))\n",
    "trump_mentioned_nouns.columns = ['Text']\n",
    "for i in range(0, len(trump_mentioned_text)):\n",
    "    nouns = [word for (word, pos) in trump_mentioned_text.iloc[i] if is_noun(pos)]\n",
    "    nouns = ' '.join(nouns)\n",
    "    trump_mentioned_nouns.iloc[i] = nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Text \n",
    "trump_mentioned_nouns['Text'] = trump_mentioned_nouns['Text'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.099*\"trump\" + 0.019*\"maga\" + 0.013*\"people\" + 0.011*\"thats\" + 0.009*\"vote\" + 0.008*\"amp\" + 0.006*\"time\" + 0.006*\"youre\" + 0.006*\"fact\" + 0.006*\"racist\"\n",
      "Topic: 1 Word: 0.026*\"trump\" + 0.012*\"vote\" + 0.010*\"amp\" + 0.010*\"maga\" + 0.010*\"tax\" + 0.009*\"woman\" + 0.007*\"donald\" + 0.007*\"thanks\" + 0.006*\"love\" + 0.006*\"watch\"\n",
      "Topic: 2 Word: 0.021*\"trump\" + 0.018*\"clinton\" + 0.018*\"country\" + 0.015*\"amp\" + 0.013*\"time\" + 0.010*\"lie\" + 0.009*\"obama\" + 0.009*\"president\" + 0.008*\"campaign\" + 0.007*\"people\"\n",
      "Topic: 3 Word: 0.021*\"campaign\" + 0.015*\"trump\" + 0.011*\"talk\" + 0.008*\"vote\" + 0.007*\"candidate\" + 0.007*\"love\" + 0.007*\"medium\" + 0.006*\"imwithher\" + 0.006*\"face\" + 0.006*\"voter\"\n",
      "Topic: 4 Word: 0.029*\"trump\" + 0.017*\"dont\" + 0.012*\"man\" + 0.010*\"america\" + 0.010*\"poll\" + 0.008*\"law\" + 0.008*\"clinton\" + 0.007*\"gop\" + 0.006*\"vote\" + 0.006*\"people\"\n",
      "Topic: 5 Word: 0.022*\"people\" + 0.016*\"trump\" + 0.013*\"way\" + 0.013*\"show\" + 0.008*\"amp\" + 0.008*\"support\" + 0.007*\"racist\" + 0.007*\"need\" + 0.006*\"question\" + 0.006*\"email\"\n",
      "Topic: 6 Word: 0.024*\"amp\" + 0.014*\"look\" + 0.013*\"nevertrump\" + 0.012*\"trump\" + 0.011*\"imwithher\" + 0.009*\"visit\" + 0.008*\"poll\" + 0.007*\"job\" + 0.007*\"care\" + 0.007*\"liar\"\n",
      "Topic: 7 Word: 0.026*\"trump\" + 0.016*\"president\" + 0.015*\"youre\" + 0.014*\"thats\" + 0.010*\"word\" + 0.008*\"im\" + 0.007*\"donaldtrump\" + 0.007*\"nevertrump\" + 0.007*\"work\" + 0.006*\"time\"\n",
      "Topic: 8 Word: 0.036*\"nevertrump\" + 0.031*\"trump\" + 0.009*\"amp\" + 0.008*\"vote\" + 0.008*\"maga\" + 0.007*\"campaign\" + 0.007*\"help\" + 0.006*\"part\" + 0.006*\"lie\" + 0.006*\"donaldtrump\"\n",
      "Topic: 9 Word: 0.041*\"trump\" + 0.019*\"vote\" + 0.015*\"campaign\" + 0.008*\"amp\" + 0.008*\"donaldtrump\" + 0.008*\"president\" + 0.007*\"please\" + 0.007*\"tweet\" + 0.007*\"medium\" + 0.007*\"wait\"\n"
     ]
    }
   ],
   "source": [
    "trump_text = trump_mentioned_nouns.Text.tolist()\n",
    "dictionary_trump = corpora.Dictionary(trump_text)\n",
    "doc_term_matrix_trump = [dictionary_trump.doc2bow(doc) for doc in trump_text]\n",
    "Lda_trump = gensim.models.ldamodel.LdaModel\n",
    "ldamodel_trump = gensim.models.LdaMulticore(doc_term_matrix_trump, num_topics=10, id2word=dictionary_trump, passes=2, workers=4)\n",
    "for idx, topic in ldamodel_trump.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test specific document how it would have been classified \n",
    "bow_doc_1 = doc_term_matrix_trump[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 25 (\"list\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(bow_doc_1)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_1[i][0], \n",
    "                                               dictionary_trump[bow_doc_1[i][0]], \n",
    "bow_doc_1[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.549860954284668\t \n",
      "Topic: 0.022*\"people\" + 0.016*\"trump\" + 0.013*\"way\" + 0.013*\"show\" + 0.008*\"amp\" + 0.008*\"support\" + 0.007*\"racist\" + 0.007*\"need\" + 0.006*\"question\" + 0.006*\"email\"\n",
      "\n",
      "Score: 0.05002668872475624\t \n",
      "Topic: 0.026*\"trump\" + 0.016*\"president\" + 0.015*\"youre\" + 0.014*\"thats\" + 0.010*\"word\" + 0.008*\"im\" + 0.007*\"donaldtrump\" + 0.007*\"nevertrump\" + 0.007*\"work\" + 0.006*\"time\"\n",
      "\n",
      "Score: 0.050026051700115204\t \n",
      "Topic: 0.099*\"trump\" + 0.019*\"maga\" + 0.013*\"people\" + 0.011*\"thats\" + 0.009*\"vote\" + 0.008*\"amp\" + 0.006*\"time\" + 0.006*\"youre\" + 0.006*\"fact\" + 0.006*\"racist\"\n",
      "\n",
      "Score: 0.05002580210566521\t \n",
      "Topic: 0.021*\"trump\" + 0.018*\"clinton\" + 0.018*\"country\" + 0.015*\"amp\" + 0.013*\"time\" + 0.010*\"lie\" + 0.009*\"obama\" + 0.009*\"president\" + 0.008*\"campaign\" + 0.007*\"people\"\n",
      "\n",
      "Score: 0.05002056062221527\t \n",
      "Topic: 0.036*\"nevertrump\" + 0.031*\"trump\" + 0.009*\"amp\" + 0.008*\"vote\" + 0.008*\"maga\" + 0.007*\"campaign\" + 0.007*\"help\" + 0.006*\"part\" + 0.006*\"lie\" + 0.006*\"donaldtrump\"\n",
      "\n",
      "Score: 0.050015632063150406\t \n",
      "Topic: 0.026*\"trump\" + 0.012*\"vote\" + 0.010*\"amp\" + 0.010*\"maga\" + 0.010*\"tax\" + 0.009*\"woman\" + 0.007*\"donald\" + 0.007*\"thanks\" + 0.006*\"love\" + 0.006*\"watch\"\n",
      "\n",
      "Score: 0.05000607296824455\t \n",
      "Topic: 0.021*\"campaign\" + 0.015*\"trump\" + 0.011*\"talk\" + 0.008*\"vote\" + 0.007*\"candidate\" + 0.007*\"love\" + 0.007*\"medium\" + 0.006*\"imwithher\" + 0.006*\"face\" + 0.006*\"voter\"\n",
      "\n",
      "Score: 0.05000607296824455\t \n",
      "Topic: 0.029*\"trump\" + 0.017*\"dont\" + 0.012*\"man\" + 0.010*\"america\" + 0.010*\"poll\" + 0.008*\"law\" + 0.008*\"clinton\" + 0.007*\"gop\" + 0.006*\"vote\" + 0.006*\"people\"\n",
      "\n",
      "Score: 0.05000607296824455\t \n",
      "Topic: 0.024*\"amp\" + 0.014*\"look\" + 0.013*\"nevertrump\" + 0.012*\"trump\" + 0.011*\"imwithher\" + 0.009*\"visit\" + 0.008*\"poll\" + 0.007*\"job\" + 0.007*\"care\" + 0.007*\"liar\"\n",
      "\n",
      "Score: 0.05000607296824455\t \n",
      "Topic: 0.041*\"trump\" + 0.019*\"vote\" + 0.015*\"campaign\" + 0.008*\"amp\" + 0.008*\"donaldtrump\" + 0.008*\"president\" + 0.007*\"please\" + 0.007*\"tweet\" + 0.007*\"medium\" + 0.007*\"wait\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(ldamodel_trump[bow_doc_1], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, ldamodel_trump.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trump mentioned / Negative Polarity Score / Only Nouns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(feasible, JJ), (crookedhillary, JJ), (bcit, ...\n",
       "0    [(isi, NN), (trouble, NN), (flip, NN), (get, N...\n",
       "0                                          [(omg, NN)]\n",
       "0    [(sarcasm, NN), (seriously, RB), (amazing, JJ)...\n",
       "0    [(put, NN), (hilary, JJ), (supporter, NN), (br...\n",
       "                           ...                        \n",
       "0    [(really, RB), (dont, JJ), (buy, NN), (idiot, ...\n",
       "0    [(everyone, NN), (hear, JJ), (stupid, JJ), (sa...\n",
       "0    [(clinton, NN), (want, VBP), (u, JJ), (forget,...\n",
       "0    [(joining, VBG), (administration, NN), (rumore...\n",
       "0    [(mean, JJ), (trump, NN), (speech, NN), (home,...\n",
       "Name: text_topicmodel, Length: 2446, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply function that determines the type of each word\n",
    "trump_mentioned_text = trump_mentioned_negative['text_topicmodel'].apply(lambda x: nltk.pos_tag(x))\n",
    "trump_mentioned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out the nouns for each row\n",
    "trump_mentioned_nouns = pd.DataFrame(np.zeros((len(trump_mentioned_text), 1)))\n",
    "trump_mentioned_nouns.columns = ['Text']\n",
    "for i in range(0, len(trump_mentioned_text)):\n",
    "    nouns = [word for (word, pos) in trump_mentioned_text.iloc[i] if is_noun(pos)]\n",
    "    nouns = ' '.join(nouns)\n",
    "    trump_mentioned_nouns.iloc[i] = nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Text \n",
    "trump_mentioned_nouns['Text'] = trump_mentioned_nouns['Text'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.045*\"trump\" + 0.017*\"speech\" + 0.014*\"dont\" + 0.011*\"lie\" + 0.010*\"tax\" + 0.009*\"r\" + 0.009*\"anything\" + 0.008*\"president\" + 0.007*\"release\" + 0.007*\"policy\"\n",
      "Topic: 1 Word: 0.043*\"trump\" + 0.019*\"people\" + 0.011*\"maga\" + 0.011*\"donaldtrump\" + 0.010*\"need\" + 0.009*\"supporter\" + 0.009*\"help\" + 0.008*\"amp\" + 0.008*\"tax\" + 0.006*\"speech\"\n",
      "Topic: 2 Word: 0.050*\"trump\" + 0.046*\"people\" + 0.016*\"maga\" + 0.014*\"tax\" + 0.008*\"pay\" + 0.008*\"work\" + 0.007*\"day\" + 0.007*\"doesnt\" + 0.007*\"news\" + 0.007*\"country\"\n",
      "Topic: 3 Word: 0.022*\"trump\" + 0.015*\"medium\" + 0.013*\"clinton\" + 0.012*\"thing\" + 0.012*\"dont\" + 0.011*\"maga\" + 0.008*\"amp\" + 0.007*\"u\" + 0.007*\"vote\" + 0.007*\"call\"\n",
      "Topic: 4 Word: 0.087*\"trump\" + 0.046*\"today\" + 0.044*\"pressure\" + 0.044*\"rain\" + 0.022*\"amp\" + 0.011*\"weather\" + 0.009*\"im\" + 0.008*\"nevertrump\" + 0.008*\"america\" + 0.007*\"liar\"\n",
      "Topic: 5 Word: 0.019*\"vote\" + 0.017*\"trump\" + 0.013*\"hell\" + 0.012*\"gop\" + 0.012*\"nevertrump\" + 0.010*\"wait\" + 0.008*\"immigration\" + 0.008*\"dont\" + 0.007*\"police\" + 0.007*\"donaldtrump\"\n",
      "Topic: 6 Word: 0.022*\"amp\" + 0.020*\"dont\" + 0.016*\"vote\" + 0.014*\"trump\" + 0.012*\"nevertrump\" + 0.008*\"time\" + 0.008*\"speech\" + 0.007*\"wall\" + 0.007*\"hate\" + 0.006*\"imwithher\"\n",
      "Topic: 7 Word: 0.018*\"trump\" + 0.014*\"racist\" + 0.013*\"dont\" + 0.009*\"year\" + 0.009*\"anything\" + 0.009*\"youre\" + 0.008*\"loser\" + 0.008*\"guy\" + 0.008*\"sad\" + 0.007*\"nevertrump\"\n",
      "Topic: 8 Word: 0.027*\"trump\" + 0.013*\"president\" + 0.011*\"mexico\" + 0.010*\"clinton\" + 0.008*\"hrc\" + 0.008*\"nevertrump\" + 0.008*\"sorry\" + 0.007*\"people\" + 0.006*\"u\" + 0.006*\"loser\"\n",
      "Topic: 9 Word: 0.039*\"trump\" + 0.013*\"doesnt\" + 0.011*\"america\" + 0.011*\"truth\" + 0.010*\"state\" + 0.007*\"liar\" + 0.007*\"cant\" + 0.007*\"thats\" + 0.006*\"show\" + 0.006*\"guy\"\n"
     ]
    }
   ],
   "source": [
    "trump_text = trump_mentioned_nouns.Text.tolist()\n",
    "dictionary_trump = corpora.Dictionary(trump_text)\n",
    "doc_term_matrix_trump = [dictionary_trump.doc2bow(doc) for doc in trump_text]\n",
    "Lda_trump = gensim.models.ldamodel.LdaModel\n",
    "ldamodel_trump = gensim.models.LdaMulticore(doc_term_matrix_trump, num_topics=10, id2word=dictionary_trump, passes=2, workers=4)\n",
    "for idx, topic in ldamodel_trump.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clinton mentioned / Positive Polarity Score / Only Nouns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(clearly, RB), (top, JJ), (secret, JJ), (info...\n",
       "0    [(randpaul, NN), (lying, VBG), (congress, NN),...\n",
       "0    [(randpaul, NN), (lying, VBG), (congress, NN),...\n",
       "0    [(celebrity, NN), (help, NN), (court, NN), (oh...\n",
       "0    [(trumptrain, NN), (please, NN), (read, VBP), ...\n",
       "                           ...                        \n",
       "0    [(speaking, VBG), (meeting, NN), (someone, NN)...\n",
       "0     [(call, NN), (pat, NN), (smith, NN), (liar, NN)]\n",
       "0                         [(aug, NN), (imwithher, NN)]\n",
       "0    [(neverhillary, JJ), (obama, MD), (hillaryclin...\n",
       "0    [(thank, NN), (clarifying, VBG), (hasnt, NN), ...\n",
       "Name: text_topicmodel, Length: 1409, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply function that determines the type of each word\n",
    "clinton_mentioned_text = clinton_mentioned_positive['text_topicmodel'].apply(lambda x: nltk.pos_tag(x))\n",
    "clinton_mentioned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out the nouns for each row\n",
    "clinton_mentioned_nouns = pd.DataFrame(np.zeros((len(clinton_mentioned_text), 1)))\n",
    "clinton_mentioned_nouns.columns = ['Text']\n",
    "for i in range(0, len(clinton_mentioned_text)):\n",
    "    nouns = [word for (word, pos) in clinton_mentioned_text.iloc[i] if is_noun(pos)]\n",
    "    nouns = ' '.join(nouns)\n",
    "    clinton_mentioned_nouns.iloc[i] = nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Text \n",
    "clinton_mentioned_nouns['Text'] = clinton_mentioned_nouns['Text'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.032*\"imwithher\" + 0.011*\"trump\" + 0.010*\"hour\" + 0.010*\"people\" + 0.009*\"care\" + 0.009*\"image\" + 0.009*\"shes\" + 0.008*\"join\" + 0.008*\"hold\" + 0.007*\"monica\"\n",
      "Topic: 1 Word: 0.012*\"trump\" + 0.011*\"people\" + 0.011*\"youre\" + 0.010*\"day\" + 0.010*\"hillaryclinton\" + 0.009*\"shes\" + 0.008*\"america\" + 0.007*\"maga\" + 0.007*\"email\" + 0.007*\"support\"\n",
      "Topic: 2 Word: 0.015*\"imwithher\" + 0.014*\"trump\" + 0.012*\"r\" + 0.011*\"way\" + 0.010*\"hillaryclinton\" + 0.009*\"show\" + 0.009*\"voter\" + 0.006*\"team\" + 0.006*\"scandal\" + 0.006*\"votetrump\"\n",
      "Topic: 3 Word: 0.024*\"amp\" + 0.018*\"maga\" + 0.013*\"woman\" + 0.012*\"imwithher\" + 0.011*\"people\" + 0.010*\"support\" + 0.010*\"hillaryclinton\" + 0.009*\"love\" + 0.008*\"trump\" + 0.006*\"r\"\n",
      "Topic: 4 Word: 0.054*\"trump\" + 0.029*\"clinton\" + 0.020*\"imwithher\" + 0.010*\"president\" + 0.007*\"campaign\" + 0.006*\"liar\" + 0.006*\"supporter\" + 0.006*\"everything\" + 0.006*\"show\" + 0.006*\"poll\"\n",
      "Topic: 5 Word: 0.021*\"amp\" + 0.013*\"vote\" + 0.013*\"imwithher\" + 0.010*\"email\" + 0.009*\"watch\" + 0.009*\"people\" + 0.009*\"question\" + 0.009*\"trump\" + 0.007*\"hillaryclinton\" + 0.007*\"word\"\n",
      "Topic: 6 Word: 0.018*\"trump\" + 0.016*\"clinton\" + 0.014*\"email\" + 0.013*\"time\" + 0.013*\"country\" + 0.013*\"amp\" + 0.011*\"campaign\" + 0.010*\"vote\" + 0.010*\"lie\" + 0.009*\"tax\"\n",
      "Topic: 7 Word: 0.029*\"imwithher\" + 0.023*\"amp\" + 0.014*\"clinton\" + 0.012*\"foundation\" + 0.010*\"hillaryclinton\" + 0.010*\"trump\" + 0.010*\"obama\" + 0.009*\"thank\" + 0.009*\"get\" + 0.009*\"woman\"\n",
      "Topic: 8 Word: 0.031*\"trump\" + 0.026*\"vote\" + 0.018*\"medium\" + 0.013*\"time\" + 0.010*\"amp\" + 0.010*\"imwithher\" + 0.008*\"hillary\" + 0.008*\"president\" + 0.007*\"isi\" + 0.007*\"putin\"\n",
      "Topic: 9 Word: 0.017*\"amp\" + 0.012*\"trump\" + 0.011*\"clinton\" + 0.010*\"campaign\" + 0.010*\"lie\" + 0.009*\"imwithher\" + 0.008*\"hillaryclinton\" + 0.007*\"lot\" + 0.007*\"fraud\" + 0.007*\"money\"\n"
     ]
    }
   ],
   "source": [
    "clinton_text = clinton_mentioned_nouns.Text.tolist()\n",
    "dictionary_clinton = corpora.Dictionary(clinton_text)\n",
    "doc_term_matrix_clinton = [dictionary_clinton.doc2bow(doc) for doc in clinton_text]\n",
    "Lda_clinton = gensim.models.ldamodel.LdaModel\n",
    "ldamodel_clinton = gensim.models.LdaMulticore(doc_term_matrix_clinton, num_topics=10, id2word=dictionary_clinton, passes=2, workers=4)\n",
    "for idx, topic in ldamodel_clinton.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clinton mentioned / Negative Polarity Score / Only Nouns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply function that determines the type of each word\n",
    "clinton_mentioned_text = clinton_mentioned_negative['text_topicmodel'].apply(lambda x: nltk.pos_tag(x))\n",
    "clinton_mentioned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out the nouns for each row\n",
    "clinton_mentioned_nouns = pd.DataFrame(np.zeros((len(clinton_mentioned_text), 1)))\n",
    "clinton_mentioned_nouns.columns = ['Text']\n",
    "for i in range(0, len(clinton_mentioned_text)):\n",
    "    nouns = [word for (word, pos) in clinton_mentioned_text.iloc[i] if is_noun(pos)]\n",
    "    nouns = ' '.join(nouns)\n",
    "    clinton_mentioned_nouns.iloc[i] = nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Text \n",
    "clinton_mentioned_nouns['Text'] = clinton_mentioned_nouns['Text'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinton_text = clinton_mentioned_nouns.Text.tolist()\n",
    "dictionary_clinton = corpora.Dictionary(clinton_text)\n",
    "doc_term_matrix_clinton = [dictionary_clinton.doc2bow(doc) for doc in clinton_text]\n",
    "Lda_clinton = gensim.models.ldamodel.LdaModel\n",
    "ldamodel_clinton = gensim.models.LdaMulticore(doc_term_matrix_clinton, num_topics=10, id2word=dictionary_clinton, passes=2, workers=4)\n",
    "for idx, topic in ldamodel_clinton.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
